---
title: 'Reflections on an old article I wrote'
sourceURL: 'https://medium.com/@dannysmith/breaking-down-problems-its-hard-when-you-re-learning-to-code-f10269f4ccd5'
draft: false
pubDate: 2025-09-01
---

So seven years hence I'm re-reading this, and... this paragraph applies even bloody more in 2025 if we replace googling and stackoverflow with "talking with Large Language Models".
I'm generally bullish re LLMs as far as speeding up coding. But I'm the opposite opposite as far as learning and what I wrote in this article is concerned.

Like StackOverflow in 2018, LLMs are very good at knowing how to solve well-defined, general-case problems which can be defined with some specificity. And like StackOverflow in 2018, they are shit at solving ill-defined general technical problems... especially when those problems exist in a niche business domain.

Relevant aside...

It pains me to think that a meaningful chunk of people will probably find this note because they're _finding it hard to break down problems when learning to code_ and will end up engaging with it via some AI-summary rather than by actually reading it. And then move on to the next thing without taking anything at all meaningful from my 2018 words besides "man coding sounds hard". I hope I'm wrong here.
