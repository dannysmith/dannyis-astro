---
title: How I'm Coding with LLMs in Nov '25
slug: coding-with-llms-oct-25
draft: true
pubDate: 2025-11-01
---

import { BookmarkCard, Callout, Embed, IntroParagraph } from '@components/mdx';

<IntroParagraph>
For the last three months or so I've been working on [Astro Editor](http://astroeditor.danny.is/), a Markdown editor for [Astro](https://astro.build/) sites built with [Tauri](https://v2.tauri.app/) and React. What started as an extercise in learning how to work effectively with AI coding agents at a basic level very quickly turned into an exercise in learning how to use them to build **decent quality** codebases. I've deliberatly tried to hand-write as little code as possible, but I can't really call Astro Editor *vibe-coded* because I've read about 60-70% of the codebase. I'm still learning, but here's where I'm at right now when it comes to setting up for success with AI coding agents.
</IntroParagraph>

## Basic Toolset

I use Cursor as my primary editor, primarily because the AI tab-completion is still the best out there for the times when I'm hand-coding. I don't make much use of the agentic features at the moment, except occasionally when I'm working on some visual design tasks. I've drastically slimmed down the number of extensions I use thanks to AI tools, but still find ESLint, Prettier, path intellisense and the like helpful.

ChatGPT with GPT-5 thinking is sometimes invaulable for helping me refine task docs before I give them to Claude Code, and is my go-to for things like image generation. I also use it and Claude Desktop for any non-technical "deep research" tasks which require extensive digging about on the internet.

I talk to my computer using [VoiceInk](/notes/voiceink).

### The Main Tool: Claude Code

I use Claude Code running in [Ghostty](/notes/ghostty-terminal) as my main AI Agent. For the most part I'm running a couple of instances of it - one working on a well-defined task and the other working out a plan for the next task.

I've messed about with multiple instances and worktrees but for all the hype about *"running twenty agents in parallel if you wanna be a 10x dev"*, this introducs way too much **cognative debt** for my liking. Even if I properly code-review all the output, I'm never going to develop a sufficiently robust mental model of the codebase unless I spend a significant amount of time looking over Claude's shoulder while it works. There are a few exceptions (small clearly-defined bugfixes etc). I guess my rule is *"if a human was doing this would I rather pair with them or review the PR after?"*

We'll get into more complex stuff later, but some basic Claude Code advice:

- Use the best model available *(at time of writing this is Sonnet 4.5, which is excellent for most coding tasks)*
- **ALWAYS** use thinking mode. Really.
- Avoid loading a million MCPs - they eat up tokens. I only have [Context7](https://context7.com/) by default in most projects.
- Add a [hook which pings you with an OS Notification](https://github.com/dannysmith/dotfiles/blob/5fd5b368bd6980a6aa5736a8d7431064f02a5911/claude/settings.json#L87) when CC finishes a task or needs your input.
- **Clear your context window regularly, and intentionally**.
  - Pre-empt CC's Auto-Compact. It never does it at an appropriate time.
  - Favour `/clear` over `/compact`. If you must compact, do it manually at an appropriate point and give specific guidance on what to keep in context.
  - Think about the relevance of the current context window. If you've completely finished a feature it makes sense to `/clear` even if you have plenty of space left. But if your next task is writing a test for that feature, CC will do a better job if you *don't* clear first, because it already has a load of relevant info in the context window. Likewise if you want it to write a good commit message for the feature. That said... if you've been down a load of dead-ends in the current session, the context will include a bunch of stuff that ended up being *irelevant*. So you might be better off with a clean slate.


## Start with a Walking Skeleton

> A walking skeleton is a minimal implementation of a system that includes just enough functionality to be deployed, integrated, and tested end-to-end. It provides a basic architectural structure for the project, allowing developers to build upon it incrementally.

Whether you're starting a new project or working in a huge legacy codebase, you need to make sure you have a framework which is...

1. **A skeleton** ‚Äì Skeletons exist to provide a perdictable structure on which future meat can be hung.
2. **Able to walk by itself** ‚Äì Everything should work even without any meat.

In a greenfield project, a walking skeleton is likeley to include:

- A logical directory structure with conventions for where files should live and how they should be named.
- A working "boilerplate" system with sensible config and defaults. Think "hello world" done well.
- Fully-configured linters, formatters and static analysis tools which are easy to run.
- A working test framework with everything you're gonna need to write good tests.
- A logically organised repository of developer documentation which we can expand over time. *It's okay if much of this is sparse to begin with... it's a skeleton üíÄü¶¥*
- A working CI/CD pipeline with sensible quality gates.
- A well-organised set of AI-specific documents explaining how all of the above works (think `CLAUDE.md`, CC Commands, Cursor Rules etc)

None of this is specific to working with AI: I learned long ago that this kinda setup is nececarry for any new project that's gonna be around for a while. Especially if I'm gonna get other people involved.

A good walking skeleton brings some important things when working with AI:

1. It forces **you** (the responsible human) to think carefully about how you want your codebase & system to work at a high level. And also how you want AI Agents (and humans) to work with you on it. Which really fucking matters in the long-run.
2. It requires a bunch of up-front decisions about technologies, tools & engineering philosophies. While ChatGPT can help you out with research, no current LLM is capable of making these decisions as well as you. Try one-shotting a non-trivial app if you don't believe me.
3. A *walking* skeleton is already **working software**, even if it does nothing useful. "Still working" is a *very* effective performance baseline for both humans and LLMs.
4. If **you** understand the skeleton and how it should walk, it's extremely obvious when Mr Claude is trying to squeeze a pair of lungs into an eye socket. (If you let Mr Claude design the skeleton and it's movement you'll be thinking "wait maybe that's meant to be there?!?").
5. Like humans, AI agents perform best when given creative freedom **within unambiguoius guardrails** and a **clear goal to aim at**. A good walking skeleton provides a lot of guardrails by definition.
6. A good walking skeleton gives LLMs something concrete to work with (idiomatic patterns, concrete examples etc).

### Choosing a tech stack

Any *reasonable* tech stack should work if you choose boring technology over [web scale](https://youtu.be/b2F-DItXtZs?si=-J0bT_T0JAaU7pz6). AI-friendliness should not be a big consideration here, but in general *the more boring and old and widely-used* your tech is, the better LLMs understand it.

My only real guidance re languages is: choose those with strong opinions and guardrails. Typescript over JS (because typed langs are good). But also Rails over Ruby. If that sounds weird... ruby is a super permissive language by design. Rails, on the other hand, is **incredibly** opinionated about everything.

When it comes to web apps, there's a bit more sublety tho. You'll almost certainally have an easier life with this stack:

- **React** ‚Äì because everything is bloody react these days.
- **Tailwind** ‚Äì because CSS is much harder to **really grok** than anyone gives it credit for. I've been a CSS nerd for ~20 years and I still struggle with the *conceptual* mental models required. LLMs are incapable of conceptual mental models, but amazing at patterns. **Tailwind is mostly patterns**. Especially when paired with...
- **shadcn/ui** ‚Äì Has become the de facto UI component library for React/Tailwind apps. 



## Guardrails

### Static analysis and tests
- Typescript
- ESLint
- React Compiler
- Prettier
- Rust formatter & Clippy
- Unit Tests
- AST Grep
- Knip
- jscpd

### Developer Documentation

### CodeRabbit

## The Claude Setup

### Global

### Project-Local

  - Agents
  - Commands


## The Development Cycle

1. Plan
   - Dictate your requirements into a markdown doc
   - Have AI reserach best approaches
   - Have AI build a god technical plan
2. Execute
   - Have AI work through the plan and stop after each phase.
   - Ask AI to review its work and ensure conformity with your `architecture.md` doc.
   - Manually test and work with AI to fix any issues one at a time.
   - Have it run some `check:all` script which typechecks, lints, formats all code and runs all tests.
3. Clean up
   - At the end of each feature, ask AI to clean up any comments, logs etc.
   - Have AI document any new patterns in the simplest way possible and update CLAUDE.md as needed.
-

## What's Next?

Claude Skills! The whole progressive disclosure thing should make itmuch easier to provide all the tools, instructions and context  the LLMs need *when theyneed it*, and without bloating the context window. I'm hoping they'll allow me to consolidate & simplify a lot of the stuff I mentioned in this article into something a bit more coherent. I think my favourite thing about Skills is how simple the *human* mental model for them is ‚Äì even with fairly complex setups, Skills are easy for humans to reason about.

As an example, imagine a **"Looking Stuff Up" Skill** which CC should always use when looking up documentation. It might include:

- A `SKILL.md` with simple instructions and rules for looking stuff up effectively and quickly.
- Access to multiple documentation MCPs (eg. Context7), with instructions on how to use them *well*.
- A set of CLI tools or scripts to for doing stuff like fetching full web pages as markdown, again with clear instructions on their use.
- Detailed instructions for using `WebSearch`, `WebFetch` and research-specific Sub-Agents to conduct deep, detailed research.
- Detailed instructions for how to conduct various different types of research, including how to make use of historical information in the project (eg. files in `docs/tasks-done`, closed GitHub issues etc)

I'll share fuller thoughts on this once I've spent some time with it. In the meantime, Han Lee wrote a [great deep dive on Claude Skills](https://leehanchung.github.io/blogs/2025/10/26/claude-skills-deep-dive/) that's worth reading.


## Don't be scared to do ad-hoc things

# [NOTES]

The belowis from https://simonwillison.net/2025/Sep/29/armin-ronacher-90/ and is relevant here.

Armin Ronacher: 90% (via) The idea of AI writing "90% of the code" to-date has mostly been expressed by people who sell AI tooling.

Over the last few months, I've increasingly seen the same idea come coming much more credible sources.

Armin is the creator of a bewildering array of valuable open source projects - Flask, Jinja, Click, Werkzeug, and many more. When he says something like this it's worth paying attention:

For the infrastructure component I started at my new company, I‚Äôm probably north of 90% AI-written code.

For anyone who sees this as a threat to their livelihood as programmers, I encourage you to think more about this section:

It is easy to create systems that appear to behave correctly but have unclear runtime behavior when relying on agents. For instance, the AI doesn‚Äôt fully comprehend threading or goroutines. If you don‚Äôt keep the bad decisions at bay early it, you won‚Äôt be able to operate it in a stable manner later.

Here‚Äôs an example: I asked it to build a rate limiter. It ‚Äúworked‚Äù but lacked jitter and used poor storage decisions. Easy to fix if you know rate limiters, dangerous if you don‚Äôt.

In order to use these tools at this level you need to know the difference between goroutines and threads. You need to understand why a rate limiter might want to"jitter" and what that actually means. You need to understand what "rate limiting" is and why you might need it!

These tools do not replace programmers. They allow us to apply our expertise at a higher level and amplify the value we can provide to other people.
